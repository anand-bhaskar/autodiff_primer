{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab --no-import-all\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import ad\n",
    "from ad import adnumber\n",
    "from ad.admath import *\n",
    "\n",
    "# Plotting imports \n",
    "# Comment these lines if you don't have seaborn installed\n",
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "import scipy.stats\n",
    "import scipy.optimize\n",
    "\n",
    "matplotlib.rcParams['ytick.labelsize'] = 16\n",
    "matplotlib.rcParams['xtick.labelsize'] = 16\n",
    "matplotlib.rcParams['axes.labelsize'] = 20\n",
    "matplotlib.rcParams['legend.fontsize'] = 20\n",
    "matplotlib.rcParams['text.usetex'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = adnumber(5.0)\n",
    "print \"x = \", x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = x**2\n",
    "print \"y = x**2\"\n",
    "\n",
    "print \"y = \", y\n",
    "print \"dy/dx = \", y.d(x)\n",
    "print \"d^2y/dx^2 = \", y.d2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = tanh(x)\n",
    "print \"y = tanh(x)\"\n",
    "\n",
    "print \"y = \", y\n",
    "print \"dy/dx = \", y.d(x)\n",
    "print \"d^2y/dx^2 = \", y.d2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing AD vs finite-differences for $f(x) = x \\sin(1/x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = adnumber(np.linspace(0.001, 0.1, 101))\n",
    "\n",
    "f = lambda x: x*sin(1./x)\n",
    "gradf = lambda x: sin(1./x) - 1./x*cos(1./x)\n",
    "\n",
    "# step size for finite difference\n",
    "eps = 1.e-5\n",
    "\n",
    "# centered finite-difference\n",
    "y_fd = np.array([(f(v+0.5*eps) - f(v-0.5*eps))/eps for v in x])\n",
    "# AD\n",
    "y_ad = np.array([f(v).d(v) for v in x])\n",
    "# symbolic\n",
    "y_true = np.array([gradf(v) for v in x])\n",
    "\n",
    "# plot relative errors\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,5))\n",
    "ax1.plot(x, (y_fd-y_true)/y_true, label=\"Finite difference\")\n",
    "ax2.plot(x, (y_ad-y_true)/y_true, label=\"AD\")\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.set_xlabel(\"$x$\")\n",
    "    ax.set_ylabel(\"Relative error in $df/dx$\")\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients and Hessians (derivatives wrt multiple variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute log-likelihood with gradient and Hessian of a multinomial distribution\n",
    "\n",
    "# parameters\n",
    "p = np.array(adnumber([0.1, 0.2, 0.3, 0]))\n",
    "# make the proportions sum to 1 \n",
    "p[-1] = 1. - sum(p[:-1])\n",
    "\n",
    "# observations\n",
    "n = np.array([3, 20, 12, 3])\n",
    "\n",
    "# log-likehood\n",
    "log_lik = sum(n * np.array(log(p)))\n",
    "\n",
    "# derivatives wrt each parameter\n",
    "for i in range(len(p)-1):\n",
    "    print \"dL/dp%d\" % i, log_lik.d(p[i])\n",
    "print\n",
    "\n",
    "# derivatives wrt each pair of parameters\n",
    "for i in range(len(p)-1):\n",
    "    for j in range(i, len(p)-1):\n",
    "        print \"d^2L/dp%dp%d\" % (i,j), log_lik.d2c(p[i], p[j])\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convenience functions\n",
    "print \"Gradient\"\n",
    "print log_lik.gradient(p[:-1])\n",
    "print\n",
    "\n",
    "print \"Hessian\"\n",
    "print np.array(log_lik.hessian(p[:-1]))\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example application: maximum-likelihood haplotype frequency estimation from genotype data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haplotype frequencies at two loci $\\mathbf{p} \\in \\Delta_3$ <br/>\n",
    "Sample $n$ haplotypes, $h_{i1}, h_{i2} \\sim \\text{Categorical}(\\mathbf{p})$ <br/>\n",
    "Genotypes $g_i = h_{i1} + h_{i2}$ <br/>\n",
    "Problem: Given $n$ genotypes $\\{ g_1, \\ldots, g_n \\}$, recover $\\mathbf{p}$ <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def neg_log_lik(x, obs_geno_locus1, obs_geno_locus2):\n",
    "    \"\"\"\n",
    "    Returns the negative log-likelihood (because we will minimize) of observing the \n",
    "    genotype data given by a vector of genotypes obs_geno_locus1 and obs_geno_locus2 at two loci,\n",
    "    for the haplotype frequences given in x\n",
    "    \"\"\"\n",
    "    hap_freq = np.reshape(x, (2,2))\n",
    "    hap_freq = hap_freq / np.sum(hap_freq)\n",
    "    geno_freq = np.zeros((3, 3), dtype=object)\n",
    "    \n",
    "    log_lik = 0.\n",
    "\n",
    "    # if genotypes at both loci are known\n",
    "    # compute the two-fold convolution of the haplotype frequency distribution\n",
    "    # go over each of the 4 possibilities for the first and second haplotypes\n",
    "    for hap1_locus1 in range(0, 1+1):\n",
    "        for hap1_locus2 in range(0, 1+1):\n",
    "            hap1_freq = hap_freq[hap1_locus1, hap1_locus2]\n",
    "            for hap2_locus1 in range(0, 1+1):\n",
    "                for hap2_locus2 in range(0, 1+1):\n",
    "                    hap2_freq = hap_freq[hap2_locus1, hap2_locus2]\n",
    "                    # sum the haplotypes at each locus to get the genotypes at each locus\n",
    "                    geno_locus1 = hap1_locus1 + hap2_locus1\n",
    "                    geno_locus2 = hap1_locus2 + hap2_locus2\n",
    "                    # add the contribution of this haplotype combination towards the genotype probability\n",
    "                    geno_freq[geno_locus1, geno_locus2] += hap1_freq * hap2_freq\n",
    "\n",
    "    for geno_locus1 in range(0, 2+1):\n",
    "        for geno_locus2 in range(0, 2+1):\n",
    "            n_geno = np.sum((obs_geno_locus1 == geno_locus1) & (obs_geno_locus2 == geno_locus2))\n",
    "            log_lik += n_geno * log(geno_freq[geno_locus1, geno_locus2])\n",
    "\n",
    "    # include data where one of the loci might have missing data\n",
    "    for geno in range(0, 2+1):\n",
    "        # locus 1 known, locus 2 unknown\n",
    "        n_geno = np.sum((obs_geno_locus1 == geno) & np.isnan(obs_geno_locus2))\n",
    "        log_lik += n_geno * log(sum(geno_freq[geno, :]))\n",
    "\n",
    "        # locus 1 unknown, locus 2 known\n",
    "        n_geno = np.sum(np.isnan(obs_geno_locus1) & (obs_geno_locus2 == geno))\n",
    "        log_lik += n_geno * log(sum(geno_freq[:, geno]))\n",
    "\n",
    "    return -log_lik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the Jacobian and Hessian of the negative log likelihood\n",
    "grad_neg_log_lik, hess_neg_log_lik = ad.gh(neg_log_lik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We don't need equality constraints since we rescale the variables to get\n",
    "# frequencies\n",
    "#\n",
    "# def eq_constraints(x):\n",
    "#     \"\"\"Only equality constraint is that the frequencies sum to 1\"\"\"\n",
    "#     return np.array([np.sum(x) - 1.])\n",
    "\n",
    "# jac_eq_constraints, hess_eq_constraints = ad.gh(eq_constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_genotypes(n, hap_freq, mask_frac=0.):\n",
    "    \"\"\" Samples n genotypes, where the haplotypes are drawn independently from hap_freq,\n",
    "    and a fraction mask_frac of the genotype entries are masked at one locus\n",
    "    \"\"\"\n",
    "    obs_geno_locus1 = []\n",
    "    obs_geno_locus2 = []\n",
    "\n",
    "    hap_dist = scipy.stats.rv_discrete(values=(range(4), hap_freq))\n",
    "    obs_haps = hap_dist.rvs(size=2*n)\n",
    "\n",
    "    obs_geno_locus1 = obs_haps / 2\n",
    "    obs_geno_locus1 = np.array(obs_geno_locus1[::2] + obs_geno_locus1[1::2], dtype=float)\n",
    "\n",
    "    obs_geno_locus2 = obs_haps % 2\n",
    "    obs_geno_locus2 = np.array(obs_geno_locus2[::2] + obs_geno_locus2[1::2], dtype=float)\n",
    "\n",
    "    perm = np.random.permutation(n)\n",
    "    obs_geno_locus1[perm[0:int(mask_frac*n)]] = np.nan\n",
    "\n",
    "    perm = np.random.permutation(n)\n",
    "    obs_geno_locus2[perm[0:int(mask_frac*n)]] = np.nan\n",
    "\n",
    "    return obs_geno_locus1, obs_geno_locus2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sample some data from the model\n",
    "n = 1000\n",
    "p = [0.1,0.2,0.3,0.4]\n",
    "obs_geno_locus1, obs_geno_locus2 = sample_genotypes(1000, p, mask_frac=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pick an initialization point\n",
    "np.random.seed(0)\n",
    "init_hap_freq = np.random.rand(4)\n",
    "init_hap_freq /= np.sum(init_hap_freq)\n",
    "\n",
    "mle = scipy.optimize.minimize(neg_log_lik, init_hap_freq, args=(obs_geno_locus1, obs_geno_locus2), \n",
    "                              method='SLSQP', \n",
    "                              jac=grad_neg_log_lik, bounds=[(1., None)]*4,\n",
    "                              #constraints=({'type': 'eq', 'fun': eq_constraints}),\n",
    "                              options={'disp': True})\n",
    "x_sum = np.sum(mle.x)\n",
    "print mle.x / x_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# using finite difference instead of the AD jacobian\n",
    "np.random.seed(0)\n",
    "init_hap_freq = np.random.rand(4)\n",
    "init_hap_freq /= np.sum(init_hap_freq)\n",
    "\n",
    "mle = scipy.optimize.minimize(neg_log_lik, init_hap_freq, args=(obs_geno_locus1, obs_geno_locus2), \n",
    "                              method='SLSQP', \n",
    "                              bounds=[(1., None)]*4,\n",
    "                              options={'disp': True})\n",
    "x_sum = np.sum(mle.x)\n",
    "print mle.x / x_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute asymptotic confidence intervals using the Fisher Information matrix\n",
    "fim_x = hess_neg_log_lik(mle.x, obs_geno_locus1, obs_geno_locus2)\n",
    "x_sum = np.sum(mle.x)\n",
    "\n",
    "#rescale into frequency coordinates\n",
    "#using the Jacobian of the mapping x_i = \\theta_i \\sum_j x_j\n",
    "jac = np.zeros((3,4))\n",
    "jac[:3,:3] = np.eye(3)*x_sum\n",
    "jac[:,-1] = -x_sum\n",
    "\n",
    "fim = np.dot(np.dot(jac, fim_x), jac.T)\n",
    "fim = fim[:3,:3]\n",
    "\n",
    "estimate = mle.x[:3] / x_sum\n",
    "asymptotic_covmat = np.linalg.inv(fim)\n",
    "marginal_sd = np.sqrt(np.diag(asymptotic_covmat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = scipy.stats.norm.ppf(0.975)\n",
    "ci = np.array(zip(estimate - z*marginal_sd, estimate + z*marginal_sd))\n",
    "print ci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asymptotic confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "n = 1000\n",
    "p = np.array([0.1,0.2,0.3,0.4])\n",
    "\n",
    "# number of simulation replicates for the CI calibration\n",
    "n_reps = 500\n",
    "\n",
    "mean_estimates = []\n",
    "sd_estimates = []\n",
    "\n",
    "for rep in range(n_reps):\n",
    "    # sample data\n",
    "    obs_geno_locus1, obs_geno_locus2 = sample_genotypes(n, p, mask_frac=0.01)\n",
    "    \n",
    "    # optimize parameters\n",
    "    init_hap_freq = np.random.rand(4)\n",
    "    init_hap_freq /= np.sum(init_hap_freq)\n",
    "\n",
    "    if rep % 50 == 0:\n",
    "        print rep\n",
    "        \n",
    "    mle = scipy.optimize.minimize(neg_log_lik, init_hap_freq, args=(obs_geno_locus1, obs_geno_locus2), \n",
    "                              method='SLSQP', \n",
    "                              jac=grad_neg_log_lik, bounds=[(1., None)]*4,\n",
    "                              options={'disp': False})\n",
    "    \n",
    "    # the Fisher information matrix is the Hessian of the negative log likelihood\n",
    "    fim_x = hess_neg_log_lik(mle.x, obs_geno_locus1, obs_geno_locus2)\n",
    "    x_sum = np.sum(mle.x)\n",
    "\n",
    "    #rescale into frequency coordinates\n",
    "    #using the Jacobian of the mapping x_i = \\theta_i \\sum_j x_j\n",
    "    jac = np.zeros((3,4))\n",
    "    jac[:3,:3] = np.eye(3)*x_sum\n",
    "    jac[:,-1] = -x_sum\n",
    "    \n",
    "    fim = np.dot(np.dot(jac, fim_x), jac.T)\n",
    "    fim = fim[:3,:3]\n",
    "    \n",
    "    asymptotic_covmat = np.linalg.inv(fim)\n",
    "    marginal_sd = np.sqrt(np.diag(asymptotic_covmat))\n",
    "    \n",
    "    mean_estimates.append(mle.x[:3] / x_sum)\n",
    "    sd_estimates.append(marginal_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_estimates = np.array(mean_estimates)\n",
    "sd_estimates = np.array(sd_estimates)\n",
    "p_check = np.tile(p[:3], (n_reps, 1))\n",
    "alphas = np.linspace(0.01, 1.00, 100)\n",
    "outside_ci = []\n",
    "for alpha in alphas:\n",
    "    z = scipy.stats.norm.ppf(1. - alpha/2.)\n",
    "    lbs = mean_estimates - z*sd_estimates\n",
    "    ubs = mean_estimates + z*sd_estimates\n",
    "    outside_ci.append(1. * np.sum((p_check < lbs) | (ubs < p_check), axis=0) / n_reps)\n",
    "outside_ci = np.array(outside_ci).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = [\"$x_{00}$\", \"$x_{01}$\", \"$x_{10}$\"]\n",
    "f = plt.figure(figsize=(8,5))\n",
    "for i in range(3):\n",
    "    plt.plot(alphas, outside_ci[i], label=labels[i])\n",
    "plt.plot([0,1], [0,1], label=\"Theoretical\")\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
